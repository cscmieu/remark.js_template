<!DOCTYPE html>
<html>
  <head>
    <title>PSA</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" type="text/css" href="core/fonts/mono.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/animate.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/cinescript.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/style_core.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/mermaid.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/gitgraph.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/style_ensiie.css"> 
    <link rel="stylesheet" type="text/css" href="core/css/katex.css"> 
  </head>
  <body>
    <textarea id="source" readonly>

layout: true
class: animated fadeIn middle numbers

.footnote[
`PSA` - N. Dubray - ENSIIE - 2023 - [:book:](../index.html)
]

---

# Multiprocessing

## Scope

:arrow_right: During this session, some ways to use multiprocessing in `Python` will be introduced.  
:warning: The associated concepts are the same in `C/C++`, but some limitations only exist in `Python`.

## `Python` modules

The following `Python` modules will be presented:

* `threading`
* `multiprocessing`

The following `Python` modules will **not** be presented (in these slides):

* `pymp`
* `mpi4py`

---

# Multiprocessing: introduction

.block[
## Definition ([wikipedia](https://en.wikipedia.org/wiki/Multiprocessing))
*Multiprocessing is the use of two or more central processing units (CPUs) within a single computer system. [...] the definition of multiprocessing can vary with context, mostly as a function of how CPUs are defined.*
]

.vspace[]

.hcenter[
:warning: The available architecture (hard and soft) imposes the multiprocessing capabilities.
]

---

# Multiprocessing: introduction

.row[
.w40[
## Example of a *computer system*

.tree[
*computer system*
* `center` "north america"
* `center` "europe"
    * `rack 03`
    * `rack 04`
        * `node 02`
        * `node 03`
            * `socket 00`
            * `socket 01`
                * `processor 00`
                * `processor 01`
                    * `core 12`
                    * `core 13`
                    * `core 14`
    * `rack 05`
* `center` "asia"
]
]
.w55[
## Examples of multiprocessing

:arrow_right: a task is run on all cores of a given processor.  
:arrow_right: a task is run on all cores of a given socket.  
:arrow_right: a task is run on all cores of a given node.  
:arrow_right: a task is run on all cores of a given rack.  
:arrow_right: a task is run on all cores of a given center.  
:arrow_right: a task is run on all cores.  

.vspace[]

## Examples of communication

:arrow_right: two cores of the same processor can communicate.  
:arrow_right: two cores of the same socket can communicate.  
:arrow_right: two cores of the same node can communicate.  
:arrow_right: two cores of the same rack can communicate.  
:arrow_right: two cores of the same center can communicate.  
:arrow_right: two cores can communicate.
]
]

---

# Multiprocessing: introduction

## Real-life example

:arrow_right: Calculate some heavy linear algebra problem.

### Multiprocessing and communication scheme

.tree[
`scientific code run` - `KMS` job (1 job)
* `Python` + `MPI` - process (32 nodes)
    * `OpenBLAS` + `OpenMP` - thread (2 * 28 cores)
] 

:arrow_right: Total: **1792 cores** using `MPI` and `OpenMP` communications between `process` and `thread` objects.

---

# Multiprocessing: thread / process

.block[
## Definition ([wikipedia](https://en.wikipedia.org/wiki/Process))
A **process** is an instance of a computer program that is being executed.
]

* Different `processes` can share processor(s) and/or resources (multitasking).
* Different `processes` have their own **memory**.

.vspace[]

.block[
## Definition ([wikipedia](https://en.wikipedia.org/wiki/Thread))
A **thread of execution** is the smallest sequence of programmed instructions that can be managed independently by a scheduler.
]

* A `thread` always belongs to a `process`.
* A `process` can spawn multiple `threads`.
* Multiple `threads` of the same `process` share resources (**memory**, IO, etc...).

## Communications

* `process`-to-`process`: Inter-Process Communication (IPC)
* `thread`-to-`thread`: Shared memory

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example0.py\]]
```Python
#!/usr/bin/env python3

import threading

def worker():
  print('new worker')

for i in range(8):
  threading.Thread(target = worker).start()
```

.row[
.column.w45[
## .hcenter[Shell session]

```shell
$ python2 threading/example0.py
new worker
new worker
new worker
new worker
new workernew worker
 
new worker
new worker
```
]
.column.w45[
## .hcenter[Shell session]

```shell
$ python3 threading/example0.py
new worker
new worker
new worker
new worker
new worker
new worker
new worker
new worker
```
]
]

:arrow_right: Why is the output mangled with `python2` ?

---

# Multiprocessing: `threading` module

## Create and launch a `Thread` object

There are two ways to specify which code to run:
1. give a function to the constructor, or
2. override the `run()` method.

:arrow_right: The `thread` must be started by calling the `start()` method.

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example1.py\]]
```Python
#!/usr/bin/env python3

import threading
import time

def worker():
  print('new worker')
  time.sleep(0.5)
  print('end of worker')

*t0 = threading.Thread(target = worker)
*t1 = threading.Thread()
*t1.run = worker

print('before')
*t0.start()
time.sleep(0.1)
*t1.start()
print('after')
```

## .hcenter[Shell session]

```shell
$ python3 threading/example1.py
before
new worker
new worker
after
end of worker
end of worker
```

:arrow_right: Why doesn't the program terminate right after the **"after"** message ?

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example2.py\]]
```Python
#!/usr/bin/env python3

import threading
import time

def worker():
  print('new worker')
  time.sleep(0.5)
  print('end of worker')

t0 = threading.Thread(target = worker)
t1 = threading.Thread()
*t0.daemon = t1.daemon = True
t1.run = worker

print('before')
t0.start()
time.sleep(0.1)
t1.start()
print('after')
```

## .hcenter[Shell session]

```shell
$ python3 threading/example2.py
before
new worker
new worker
after
```

:arrow_right: A `Python` program exits if all the remaining threads are `daemon` threads.  
:arrow_right: The `daemon` property value is inherited from the creating thread.

---

# Multiprocessing: `threading` module

## Wait for a daemon thread to finish

:arrow_right: Use the `join()` method.  
:arrow_right: This blocks the calling thread until the other thread terminates or raises an exception.  
:arrow_right: An optional timeout value can be specified (`join(3.2)` will wait for 3.2s).

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example3.py\]]
```Python
#!/usr/bin/env python3

import threading
import time

def worker():
  print('new worker')
  time.sleep(0.5)
  print('end of worker')

t0 = threading.Thread(target = worker)
t1 = threading.Thread(target = worker)
t0.daemon = t1.daemon = True

print('before')
t0.start()
time.sleep(0.1)
t1.start()
print('after')
*t0.join()
```

## .hcenter[Shell session]

```shell
$ python3 threading/example3.py
before
new worker
new worker
after
*end of worker
```


---

# Multiprocessing: `threading` module

## Pass arguments to a `Thread` object

:arrow_right: Use the `args` keyword of the `Thread` constructor.  
:warning: Pass a `tuple` object.

## .hcenter[\[threading/example4.py\]]
```Python
#!/usr/bin/env python3

import threading

def worker(n):
  print('new worker: %d' % (n))

for i in range(8):
* threading.Thread(target = worker, args = (i,)).start()
```

.row[
.column.w45[
## .hcenter[Shell session]

```shell
$ python2 threading/example4.py
new worker: 0new worker: 1
 new worker: 2
new worker: 3
 new worker: 5new worker: 4
 new worker: 6
new worker: 7
```
]
.column.w45[
## .hcenter[Shell session]

```shell
$ python3 threading/example4.py
new worker: 0
new worker: 1
new worker: 2
new worker: 3
new worker: 4
new worker: 5
new worker: 6
new worker: 7
```
]
]

:warning: There is no *nice* way to pass arguments when overriding the `run()` method.

---

# Multiprocessing: `threading` module

## Mangled output ?

```shell
$ python2 threading/example4.py
new worker: 0new worker: 1

 new worker: 2
new worker: 3
 new worker: 5new worker: 4
 new worker: 6

new worker: 7

```

## Do not use `print()`

:arrow_right: Use the `logging` module.  
:arrow_right: Customize the log format to show the thread's name.

Check [`logging` documentation](https://docs.python.org/2/library/logging.html) for details and examples.

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example5.py\]]
```Python
#!/usr/bin/env python3

*import logging
import threading

*logging.basicConfig(level = logging.DEBUG,
*                   format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s',
*                   datefmt='%Y-%m-%d %H:%M:%S',
*                  )

def worker(n):
* logging.debug('new worker: %d' % (n))

*logging.debug("start")
for i in range(8):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

## .hcenter[Shell session]

```shell
$ python3 threading/example5.py
2023-05-02 15:57:24.697 [DEBUG] (MainThread) start
2023-05-02 15:57:24.698 [DEBUG] (THREAD-0) new worker: 0
2023-05-02 15:57:24.698 [DEBUG] (THREAD-1) new worker: 1
2023-05-02 15:57:24.698 [DEBUG] (THREAD-3) new worker: 3
2023-05-02 15:57:24.699 [DEBUG] (THREAD-2) new worker: 2
2023-05-02 15:57:24.699 [DEBUG] (THREAD-4) new worker: 4
2023-05-02 15:57:24.699 [DEBUG] (THREAD-5) new worker: 5
2023-05-02 15:57:24.699 [DEBUG] (THREAD-6) new worker: 6
2023-05-02 15:57:24.700 [DEBUG] (THREAD-7) new worker: 7
```

---

# Multiprocessing: `threading` module

## Enumerate current threads

:arrow_right: List the current `Thread` instances with `threading.enumerate()`.  
:warning: Threads not created by `threading.Thread` will not appear.

## .hcenter[\[threading/example6.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

def worker(n):
  time.sleep(1.0)

for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()

*logging.debug(str([t.name for t in threading.enumerate()]))
```

## .hcenter[Shell session]

```shell
$ python3 threading/example6.py
2023-05-02 16:20:31.045 [DEBUG] (MainThread) ['MainThread', 'THREAD-0', 'THREAD-2', 'THREAD-1']
```

---

# Multiprocessing: `threading` module

## `Timer` class

:arrow_right: Launch a function after a specified delay.

## .hcenter[\[threading/example7.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

def worker(n):
  logging.debug("worker %d" % (n))

logging.debug("start")
for i in range(3):
  threading.Timer(i + 1.0, worker, args = (i,)).start()
logging.debug("stop ?")
```

## .hcenter[Shell session]

```shell
$ python3 threading/example7.py
2023-05-02 21:07:23.248 [DEBUG] (MainThread) start
2023-05-02 21:07:23.249 [DEBUG] (MainThread) stop ?
2023-05-02 21:07:24.249 [DEBUG] (Thread-1) worker 0
2023-05-02 21:07:25.249 [DEBUG] (Thread-2) worker 1
2023-05-02 21:07:26.249 [DEBUG] (Thread-3) worker 2
```

:arrow_right: The "countdown" can be canceled with the `cancel()` method.

---

# Multiprocessing: `threading` module

## Accesses to shared resources

* Unprotected accesses ?

## .hcenter[\[threading/example8.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*a = 0
def worker(n):
* global a
* b = a
* time.sleep(0.0001)
* a = b + 1
  logging.debug("worker %d: a = %d" % (n, a))

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

## .hcenter[Shell session]

```shell
$ python3 threading/example8.py
2023-05-02 21:23:46.490 [DEBUG] (MainThread) start
2023-05-02 21:23:46.491 [DEBUG] (THREAD-0) worker 0: a = 1
2023-05-02 21:23:46.491 [DEBUG] (THREAD-1) worker 1: a = 1
2023-05-02 21:23:46.491 [DEBUG] (THREAD-2) worker 2: a = 2
```

---

# Multiprocessing: `threading` module

:arrow_right: To protect accesses to shared resources, **synchronization** must be used.

## Thread synchronization methods

* `threading.Lock`: basic lock mechanism,
* `threading.RLock`: re-entrant lock mechanism,
* `threading.Event`: send and receive signals,
* `threading.Condition`: wait for a given state and access a shared resource.
* `threading.Semaphore`: limit the number of concurrent accesses to a resource.

---

class: top

# Multiprocessing: `threading` module

## `threading.Lock`

:arrow_right: Allows to protect shared resources from simultaneous (nefarious) accesses.

## .hcenter[\[threading/example9.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

l = threading.Lock()
a = 0
def worker(n):
* global a
  logging.debug("lock.acquire()")
  l.acquire()
  logging.debug(" lock acquired !")
  b = a
  time.sleep(0.0001)
  a = b + 1
  logging.debug("  worker %d: a = %d" % (n, a))
  logging.debug("   lock.release()")
  l.release()
  logging.debug("    lock released !")

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

--

:moneybag: Bonus question: Why "`global a`" and not "`global a, l`" or "" ?

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]

```shell
$ python3 threading/example9.py
2023-05-02 21:59:01.323 [DEBUG] (MainThread) start
2023-05-02 21:59:01.324 [DEBUG] (THREAD-0) lock.acquire()
2023-05-02 21:59:01.324 [DEBUG] (THREAD-0)  lock acquired !
2023-05-02 21:59:01.324 [DEBUG] (THREAD-1) lock.acquire()
2023-05-02 21:59:01.324 [DEBUG] (THREAD-0)   worker 0: a = 1
2023-05-02 21:59:01.324 [DEBUG] (THREAD-2) lock.acquire()
2023-05-02 21:59:01.324 [DEBUG] (THREAD-0)    lock.release()
2023-05-02 21:59:01.324 [DEBUG] (THREAD-0)     lock released !
2023-05-02 21:59:01.325 [DEBUG] (THREAD-1)  lock acquired !
2023-05-02 21:59:01.325 [DEBUG] (THREAD-1)   worker 1: a = 2
2023-05-02 21:59:01.325 [DEBUG] (THREAD-1)    lock.release()
2023-05-02 21:59:01.325 [DEBUG] (THREAD-1)     lock released !
2023-05-02 21:59:01.325 [DEBUG] (THREAD-2)  lock acquired !
2023-05-02 21:59:01.325 [DEBUG] (THREAD-2)   worker 2: a = 3
2023-05-02 21:59:01.325 [DEBUG] (THREAD-2)    lock.release()
2023-05-02 21:59:01.325 [DEBUG] (THREAD-2)     lock released !
```

## To sum up

.hcenter[
| Lock state  | released  | acquired |
| :---------: | :-------: | :------: |
| `acquire()` | OK        | wait     |
| `release()` | Exception | OK       |
]

:arrow_right: A **timeout** can be specified for `acquire()`.
To know if the lock has been acquired,
check the return value of the method (`True` means acquired).  
:bulb: To check if a lock is released **without acquiring it**, use `acquire(0)`.

---

# Multiprocessing: `threading` module

## `threading.RLock`

:arrow_right: Allows threads to acquire a **lock** more than once.  

## .hcenter[\[threading/example10.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

l = threading.Lock()
def worker(n):
  logging.debug("lock.acquire()")
  l.acquire()
  logging.debug(" lock acquired !")
  logging.debug("  lock.acquire() again ?")
  l.acquire()
  logging.debug("   lock acquired !")
  logging.debug("    lock.release()")
  l.release()
  logging.debug("     lock released !")

logging.debug("start - this program should result in a deadlock")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example10.py
2023-05-02 22:22:10.405 [DEBUG] (MainThread) start - this program should result in a deadlock
2023-05-02 22:22:10.405 [DEBUG] (THREAD-0) lock.acquire()
2023-05-02 22:22:10.405 [DEBUG] (THREAD-0)  lock acquired !
2023-05-02 22:22:10.405 [DEBUG] (THREAD-0)   lock.acquire() again ?
2023-05-02 22:22:10.406 [DEBUG] (THREAD-1) lock.acquire()
2023-05-02 22:22:10.406 [DEBUG] (THREAD-2) lock.acquire()
*[DEADLOCK]
```

:warning: Trying to acquire an acquired lock **by the same thread** will result in a **deadlock** most of the time.  
:arrow_right: Use `threading.RLock` objects instead.

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example11.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*l = threading.RLock()
def worker(n):
  logging.debug("lock.acquire()")
  l.acquire()
  logging.debug(" lock acquired !")
  logging.debug("  lock.acquire() again ?")
  l.acquire()
  logging.debug("   lock acquired !")
  logging.debug("    lock.release()")
* try:
*   while True:
*     l.release()
* except:
*   pass
  logging.debug("     lock released !")

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example11.py
2023-05-02 22:40:39.877 [DEBUG] (MainThread) start
2023-05-02 22:40:39.877 [DEBUG] (THREAD-0) lock.acquire()
2023-05-02 22:40:39.877 [DEBUG] (THREAD-0)  lock acquired !
2023-05-02 22:40:39.878 [DEBUG] (THREAD-0)   lock.acquire() again ?
2023-05-02 22:40:39.878 [DEBUG] (THREAD-1) lock.acquire()
2023-05-02 22:40:39.878 [DEBUG] (THREAD-0)    lock acquired !
2023-05-02 22:40:39.878 [DEBUG] (THREAD-2) lock.acquire()
2023-05-02 22:40:39.878 [DEBUG] (THREAD-0)     lock.release()
2023-05-02 22:40:39.878 [DEBUG] (THREAD-0)      lock released !
2023-05-02 22:40:39.878 [DEBUG] (THREAD-1)  lock acquired !
2023-05-02 22:40:39.878 [DEBUG] (THREAD-1)   lock.acquire() again ?
2023-05-02 22:40:39.878 [DEBUG] (THREAD-1)    lock acquired !
2023-05-02 22:40:39.878 [DEBUG] (THREAD-1)     lock.release()
2023-05-02 22:40:39.879 [DEBUG] (THREAD-1)      lock released !
2023-05-02 22:40:39.879 [DEBUG] (THREAD-2)  lock acquired !
2023-05-02 22:40:39.879 [DEBUG] (THREAD-2)   lock.acquire() again ?
2023-05-02 22:40:39.879 [DEBUG] (THREAD-2)    lock acquired !
2023-05-02 22:40:39.879 [DEBUG] (THREAD-2)     lock.release()
2023-05-02 22:40:39.879 [DEBUG] (THREAD-2)      lock released !
```

:arrow_right: At any time, an `RLock` object belongs to 0 or 1 thread.  
:arrow_right: Only the owner thread can increment / decrement the `RLock`'s acquiring counter.  
:arrow_right: When the `RLock`'s acquiring counter reaches 0, the lock is released.  
:bulb: Use `RLock` for recursive functions or when there is a need for a lock to have an owner.

---

# Multiprocessing: `threading` module

## `threading.Event`

:arrow_right: Very simple to use: one thread sends a signal, some other thread(s) wait for it.

## .hcenter[\[threading/example12.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

s = threading.Event()
def worker(n):
  logging.debug("waiting for signal")
  s.wait()
  logging.debug("signal received")

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
logging.debug("send signal")
s.set()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```
$ python3 threading/example12.py
2023-05-02 23:07:27.170 [DEBUG] (MainThread) start
2023-05-02 23:07:27.170 [DEBUG] (THREAD-0) waiting for signal
2023-05-02 23:07:27.171 [DEBUG] (THREAD-1) waiting for signal
2023-05-02 23:07:27.171 [DEBUG] (THREAD-2) waiting for signal
2023-05-02 23:07:27.171 [DEBUG] (MainThread) send signal
2023-05-02 23:07:27.171 [DEBUG] (THREAD-0) signal received
2023-05-02 23:07:27.171 [DEBUG] (THREAD-2) signal received
2023-05-02 23:07:27.171 [DEBUG] (THREAD-1) signal received
```

:arrow_right: A **timeout** can be specified for `wait()`.
To know if the event has been sent,
check the return value of the method (`True` means sent).  

---

# Multiprocessing: `threading` module

## `threading.Condition`

:arrow_right: A `Condition` object is like an `Event` with an associated `Lock`.  
:arrow_right: It is meant to be used e.g. in "producer to consumers" schemes.  

## Typical example

1. Some thread(s) wait for a resource to be available,
2. one thread produces or prepares the resource,  
3. then **notifies one or all of the waiting thread(s)**,
4. **one of the waiting thread(s)** gets exclusive access to the resource (lock).

---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example13.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

c = threading.Condition()
def worker(n):
  logging.debug("wait")
  c.acquire()
  c.wait()
  logging.debug("received !")
  c.release()

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
logging.debug("set condition")

for i in range(3):
  time.sleep(1.0)
  c.acquire()
  logging.debug("notify one thread")
  c.notify()
  c.release()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example13.py
2023-05-03 13:19:34.204 [DEBUG] (MainThread) start
2023-05-03 13:19:34.204 [DEBUG] (THREAD-0) wait
2023-05-03 13:19:34.205 [DEBUG] (THREAD-1) wait
2023-05-03 13:19:34.205 [DEBUG] (THREAD-2) wait
2023-05-03 13:19:34.205 [DEBUG] (MainThread) set condition
2023-05-03 13:19:35.206 [DEBUG] (MainThread) notify one thread
2023-05-03 13:19:35.207 [DEBUG] (THREAD-0) received !
2023-05-03 13:19:36.208 [DEBUG] (MainThread) notify one thread
2023-05-03 13:19:36.208 [DEBUG] (THREAD-1) received !
2023-05-03 13:19:37.209 [DEBUG] (MainThread) notify one thread
2023-05-03 13:19:37.209 [DEBUG] (THREAD-2) received !
```

:warning: A `Condition`'s lock must be acquired before using `wait()`.  
:arrow_right: A **timeout** can be specified for `wait()`.  
:arrow_right: A `wait_for()` method has been introduced in `Python3.2`, allowing to wait for a specific expression to become `True` before waking up a thread.

---

# Multiprocessing: `threading` module

## `threading.Semaphore`

:arrow_right: One of the earliest synchronization mechanisms in computer science.  
:arrow_right: Allows a given **maximum number of threads to simultaneously access a resource**.

## .hcenter[\[threading/example14.py\]]

```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*c = threading.Semaphore(2)
a = 0
def worker(n):
  global a
  logging.debug("wait")
  c.acquire()
  time.sleep(0.1)
  logging.debug("received !")
  c.release()
  logging.debug("release")

logging.debug("start")
for i in range(10):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example14.py
2023-05-03 14:30:34.591 [DEBUG] (MainThread) start
2023-05-03 14:30:34.592 [DEBUG] (THREAD-0) wait
2023-05-03 14:30:34.592 [DEBUG] (THREAD-1) wait
2023-05-03 14:30:34.592 [DEBUG] (THREAD-2) wait
2023-05-03 14:30:34.592 [DEBUG] (THREAD-3) wait
2023-05-03 14:30:34.593 [DEBUG] (THREAD-4) wait
2023-05-03 14:30:34.593 [DEBUG] (THREAD-5) wait
2023-05-03 14:30:34.593 [DEBUG] (THREAD-6) wait
2023-05-03 14:30:34.594 [DEBUG] (THREAD-7) wait
2023-05-03 14:30:34.594 [DEBUG] (THREAD-8) wait
2023-05-03 14:30:34.594 [DEBUG] (THREAD-9) wait
2023-05-03 14:30:34.692 [DEBUG] (THREAD-0) received !
2023-05-03 14:30:34.693 [DEBUG] (THREAD-1) received !
2023-05-03 14:30:34.693 [DEBUG] (THREAD-0) release
2023-05-03 14:30:34.693 [DEBUG] (THREAD-1) release
2023-05-03 14:30:34.793 [DEBUG] (THREAD-3) received !
2023-05-03 14:30:34.793 [DEBUG] (THREAD-3) release
2023-05-03 14:30:34.793 [DEBUG] (THREAD-2) received !
2023-05-03 14:30:34.794 [DEBUG] (THREAD-2) release
2023-05-03 14:30:34.893 [DEBUG] (THREAD-4) received !
2023-05-03 14:30:34.894 [DEBUG] (THREAD-4) release
2023-05-03 14:30:34.894 [DEBUG] (THREAD-5) received !
2023-05-03 14:30:34.894 [DEBUG] (THREAD-5) release
2023-05-03 14:30:34.994 [DEBUG] (THREAD-6) received !
2023-05-03 14:30:34.994 [DEBUG] (THREAD-6) release
2023-05-03 14:30:34.995 [DEBUG] (THREAD-7) received !
2023-05-03 14:30:34.995 [DEBUG] (THREAD-7) release
2023-05-03 14:30:35.094 [DEBUG] (THREAD-8) received !
2023-05-03 14:30:35.095 [DEBUG] (THREAD-8) release
2023-05-03 14:30:35.095 [DEBUG] (THREAD-9) received !
2023-05-03 14:30:35.095 [DEBUG] (THREAD-9) release
```

:arrow_right: Use `BoundedSemaphore` for a variant that can not exceed its initial maximum value.

---

# Multiprocessing: `threading` module

## Using `with` syntax for `Lock`, `RLock`, `Condition` and `Semaphore`

:arrow_right: Used as context managers for a `with` block, these objects will start the block with `acquire()` and end it with `release()`.

:arrow_right: The `with` construction is **exception-safe** and avoids forgetting the `.release()` call.

.row[
.column.w47.middle[
```Python
l = threading.Lock()

l.acquire()
do_something()
l.release()
```
]
.column.w5.middle[:arrow_right:]
.column.w47.middle[
```Python
l = threading.Lock()

with l:
  do_something()
```
]
]

---

# Multiprocessing: `threading` module

:arrow_right: Using `with` syntax to rewrite `example13.py`:

## .hcenter[\[threading/example15.py\]]

```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

c = threading.Condition()
def worker(n):
  logging.debug("wait")
* with c:
    c.wait()
    logging.debug("received !")

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
logging.debug("set condition")

for i in range(3):
  time.sleep(1.0)
* with c:
    logging.debug("notify one thread")
    c.notify()
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example15.py
2023-05-03 21:55:01.672 [DEBUG] (MainThread) start
2023-05-03 21:55:01.672 [DEBUG] (THREAD-0) wait
2023-05-03 21:55:01.673 [DEBUG] (THREAD-1) wait
2023-05-03 21:55:01.673 [DEBUG] (THREAD-2) wait
2023-05-03 21:55:01.673 [DEBUG] (MainThread) set condition
2023-05-03 21:55:02.674 [DEBUG] (MainThread) notify one thread
2023-05-03 21:55:02.675 [DEBUG] (THREAD-0) received !
2023-05-03 21:55:03.676 [DEBUG] (MainThread) notify one thread
2023-05-03 21:55:03.676 [DEBUG] (THREAD-1) received !
2023-05-03 21:55:04.677 [DEBUG] (MainThread) notify one thread
2023-05-03 21:55:04.678 [DEBUG] (THREAD-2) received !
```

:arrow_right: Same output as `threading/example13.py` (fortunately) :v:

---

# Multiprocessing: `queue` module

## `queue.Queue`

:arrow_right: Implement **thread-safe queue objects**.  
:arrow_right: Allows **multiple threads** to **push** and **pop** from queue objects.  
:arrow_right: Deals with the internal synchronization mechanisms.  
:arrow_right: Queue objects can be bounded if needed.  
:warning: `Queue.Queue` in Python2 !

## Three types of queues are provided:

1. FIFO (`queue.Queue`)
2. LIFO (`queue.LifoQueue`)
3. "priority queue" (`queue.PriorityQueue`)

## Variant

:bulb: See `collections.deque` for a variant of unbounded queues with **atomic** `append()` and `popleft()` methods (no lock required).


---

# Multiprocessing: `threading` module

## .hcenter[\[threading/example16.py\]]

```Python
#!/usr/bin/env python3

import logging
import threading
import time
import queue

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*q = queue.Queue()
def worker(n):
  while True:
    logging.debug("wait for item")
*   item = q.get()
    logging.debug("received item %d" % (item))
    time.sleep(0.2) # do something
*   q.task_done()
    logging.debug("task done")

logging.debug("start")
for i in range(3):
  t = threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,))
* t.daemon = True
  t.start()

time.sleep(1.0)
for i in range(5):
  logging.debug("append item %d to queue" % (i))
* q.put(i)

time.sleep(2.0)
```

---

# Multiprocessing: `threading` module

## .hcenter[Shell session]
```shell
$ python3 threading/example16.py
2023-05-03 15:00:45.381 [DEBUG] (MainThread) start
2023-05-03 15:00:45.382 [DEBUG] (THREAD-0) wait for item
2023-05-03 15:00:45.382 [DEBUG] (THREAD-1) wait for item
2023-05-03 15:00:45.382 [DEBUG] (THREAD-2) wait for item
2023-05-03 15:00:46.384 [DEBUG] (MainThread) append item 0 to queue
2023-05-03 15:00:46.384 [DEBUG] (MainThread) append item 1 to queue
2023-05-03 15:00:46.384 [DEBUG] (MainThread) append item 2 to queue
2023-05-03 15:00:46.384 [DEBUG] (MainThread) append item 3 to queue
2023-05-03 15:00:46.384 [DEBUG] (THREAD-1) received item 1
2023-05-03 15:00:46.384 [DEBUG] (THREAD-0) received item 0
2023-05-03 15:00:46.385 [DEBUG] (THREAD-2) received item 2
2023-05-03 15:00:46.385 [DEBUG] (MainThread) append item 4 to queue
2023-05-03 15:00:46.585 [DEBUG] (THREAD-1) task done
2023-05-03 15:00:46.585 [DEBUG] (THREAD-1) wait for item
2023-05-03 15:00:46.586 [DEBUG] (THREAD-0) task done
2023-05-03 15:00:46.586 [DEBUG] (THREAD-1) received item 3
2023-05-03 15:00:46.586 [DEBUG] (THREAD-2) task done
2023-05-03 15:00:46.586 [DEBUG] (THREAD-0) wait for item
2023-05-03 15:00:46.586 [DEBUG] (THREAD-2) wait for item
2023-05-03 15:00:46.586 [DEBUG] (THREAD-0) received item 4
2023-05-03 15:00:46.786 [DEBUG] (THREAD-1) task done
2023-05-03 15:00:46.786 [DEBUG] (THREAD-1) wait for item
2023-05-03 15:00:46.787 [DEBUG] (THREAD-0) task done
2023-05-03 15:00:46.787 [DEBUG] (THREAD-0) wait for item
```

:warning: Do not forget to call the `task_done()` method when the work associated with an item is done (allows to `join()` properly).

---

class: top

# Multiprocessing: `Python` GIL

## OS Scheduler

:arrow_right: Multithreaded `C++` code using 2 threads on 2 cores:

.vspace[]

--

.hcenter.w80[![](images/multithread.png)]

.vspace[]

--

:arrow_right: Multithreaded `Python` code using 2 threads on 2 cores:

.vspace[]

--

.hcenter.w80[![](images/multithread_gil.png)]

--

:arrow_right: Thanks to `CPython`'s **G**lobal **I**nterpreter **L**ock.

---

# Multiprocessing: `Python` GIL

.hcenter.w100[![](images/wait.png)]

---

# Multiprocessing: `Python` GIL

## What ?

* There is a **lock mechanism** in `CPython` to ensure that **only one** thread runs at a time.

## Why ?

* Because it is **very difficult** to do otherwise and keep good performances for single-threaded code.

## How to use multiple cores for multithreaded `Python` code then ?

* Most IO operations release the GIL.
* Some `Python` libraries performing computationally-intensive calculations release the GIL.

:arrow_right: **In these cases**, multithreaded `Python` code should run simultaneously on multiple cores.

## What about the other cases ?

:arrow_right: Multithreaded `Python` code **will not run simultaneously on multiple cores**.

## .red[However,]

* one can spawn threads from a `C++` module,
* one can use **something else than threads**...

---

class: top

# Multiprocessing: `multiprocessing` module

## Use the `multiprocessing` module :v:

:arrow_right: Spawn **processes** instead of **threads**.  

.vspace[]

--

## OK, so everything we've seen about threads in `Python` is useless ?

--

:arrow_right: Not at all, simply replace `threading.Thread` objects by `multiprocessing.Process` objects.  

--

```shell
$ cd examples/threading/
$ for i in *py; do sed 's/threading/multiprocessing/g' $i | sed 's/Thread/Process/g' > ../multiprocessing/$i; done
```

:bulb: The logging format should also be changed to show PIDs instead of thread names.

.vspace[]

--

:arrow_right: **Almost all previous examples** (except 6, 7, 8, 9 and 16) should work **out of the box**.

.vspace[]

.hcenter.w80[![](images/multithread.png)]

:arrow_right: Let's now check why examples 6, 7, 8, 9 and 16 do not work.
---

# Multiprocessing: `multiprocessing` module

## .hcenter[\[threading/example6.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

def worker(n):
  time.sleep(1.0)

for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()

*logging.debug(str([t.name for t in threading.enumerate()]))
```

.vspace[]

:warning: No `enumerate()` method in `multiprocessing` module.

---

# Multiprocessing: `multiprocessing` module

## .hcenter[\[threading/example7.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

def worker(n):
  logging.debug("worker %d" % (n))

logging.debug("start")
for i in range(3):
* threading.Timer(i + 1.0, worker, args = (i,)).start()
logging.debug("stop ?")
```

.vspace[]

:warning: No `Timer` object in `multiprocessing` module.

---

# Multiprocessing: `multiprocessing` module

## .hcenter[\[threading/example8.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

a = 0
def worker(n):
  global a
  b = a
  time.sleep(0.0001)
  a = b + 1
  logging.debug("worker %d: a = %d" % (n, a))

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

---

class: top

# Multiprocessing: `multiprocessing` module

## .hcenter[\[multiprocessing/example8.py\]]
```Python
#!/usr/bin/env python3

import logging
import multiprocessing
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(process)d) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

a = 0
def worker(n):
  global a
  b = a
  time.sleep(0.0001)
  a = b + 1
  logging.debug("worker %d: a = %d" % (n, a))

logging.debug("start")
for i in range(3):
  multiprocessing.Process(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

--

## .hcenter[Shell session]
```shell
$ multiprocessing/example8.py
2023-05-03 21:28:18.889 [DEBUG] (6156) start
2023-05-03 21:28:18.890 [DEBUG] (6157) worker 0: a = 1
2023-05-03 21:28:18.890 [DEBUG] (6158) worker 1: a = 1
2023-05-03 21:28:18.892 [DEBUG] (6159) worker 2: a = 1
```

--

:warning: Memory is not shared for processes.

:arrow_right: Create a **value in shared memory** using `multiprocessing.Value`. 


---

class: top

# Multiprocessing: `multiprocessing` module

## .hcenter[\[multiprocessing/example8b.py\]]
```Python
#!/usr/bin/env python3

import logging
import multiprocessing
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(process)d) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*a = multiprocessing.Value('i', 0)
*def worker(n, a):

* b = a.value
  time.sleep(0.0001)
* a.value = b + 1
* logging.debug("worker %d: a = %d" % (n, a.value))

logging.debug("start")
for i in range(3):
* multiprocessing.Process(name = 'THREAD-%01d' % (i), target = worker, args = (i, a)).start()
```

## .hcenter[Shell session]
```shell
$ multiprocessing/example8b.py
2023-05-03 21:30:49.498 [DEBUG] (6200) start
2023-05-03 21:30:49.507 [DEBUG] (6201) worker 0: a = 1
2023-05-03 21:30:49.508 [DEBUG] (6202) worker 1: a = 2
2023-05-03 21:30:49.508 [DEBUG] (6203) worker 2: a = 2
```

---

# Multiprocessing: `multiprocessing` module

## .hcenter[\[threading/example9.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*l = threading.Lock()
*a = 0
def worker(n):
* global a
  logging.debug("lock.acquire()")
  l.acquire()
  logging.debug(" lock acquired !")
  b = a
  time.sleep(0.0001)
  a = b + 1
  logging.debug("  worker %d: a = %d" % (n, a))
  logging.debug("   lock.release()")
  l.release()
  logging.debug("    lock released !")

logging.debug("start")
for i in range(3):
  threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,)).start()
```

:arrow_right: Create a **value in shared memory** using `multiprocessing.Value`. 

:arrow_right: Use a `multiprocessing.Lock` object.

---

# Multiprocessing: `multiprocessing` module

## .hcenter[\[multiprocessing/example9.py\]]
```Python
#!/usr/bin/env python3

import logging
import multiprocessing
import time

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(process)d) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*def worker(n, a, l):
  logging.debug("lock.acquire()")
  l.acquire()
  logging.debug(" lock acquired !")
  b = a.value
  time.sleep(0.2)
  a.value = b + 1
  logging.debug("  worker %d: a = %d" % (n, a.value))
  logging.debug("   lock.release()")
  l.release()
  logging.debug("    lock released !")

logging.debug("start")
*lock = multiprocessing.Lock()
*a = multiprocessing.Value('i', 0, lock = False)

for i in range(3):
* multiprocessing.Process(name = 'THREAD-%01d' % (i), target = worker, args = (i, a, lock)).start()
```

---

# Multiprocessing: `multiprocessing` module

## .hcenter[Shell session]
```shell
$ multiprocessing/example9.py
2023-05-03 21:36:46.551 [DEBUG] (6313) start
2023-05-03 21:36:46.560 [DEBUG] (6314) lock.acquire()
2023-05-03 21:36:46.560 [DEBUG] (6314)  lock acquired !
2023-05-03 21:36:46.560 [DEBUG] (6315) lock.acquire()
2023-05-03 21:36:46.560 [DEBUG] (6316) lock.acquire()
2023-05-03 21:36:46.761 [DEBUG] (6314)   worker 0: a = 1
2023-05-03 21:36:46.761 [DEBUG] (6314)    lock.release()
2023-05-03 21:36:46.761 [DEBUG] (6314)     lock released !
2023-05-03 21:36:46.761 [DEBUG] (6315)  lock acquired !
2023-05-03 21:36:46.961 [DEBUG] (6315)   worker 1: a = 2
2023-05-03 21:36:46.962 [DEBUG] (6315)    lock.release()
2023-05-03 21:36:46.962 [DEBUG] (6315)     lock released !
2023-05-03 21:36:46.962 [DEBUG] (6316)  lock acquired !
2023-05-03 21:36:47.162 [DEBUG] (6316)   worker 2: a = 3
2023-05-03 21:36:47.163 [DEBUG] (6316)    lock.release()
2023-05-03 21:36:47.163 [DEBUG] (6316)     lock released !
```

:arrow_right: Exactly the same behavior as `threading/example9.py` :v:

---

class: top

# Multiprocessing: `multiprocessing` module

## .hcenter[\[threading/example16.py\]]
```Python
#!/usr/bin/env python3

import logging
import threading
import time
import queue

logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(threadName)s) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*q = queue.Queue()
def worker(n):
  while True:
    logging.debug("wait for item")
    item = q.get()
    logging.debug("received item %d" % (item))
    time.sleep(0.2) # do something
    q.task_done()
    logging.debug("task done")

logging.debug("start")
for i in range(3):
  t = threading.Thread(name = 'THREAD-%01d' % (i), target = worker, args = (i,))
  t.daemon = True
  t.start()

time.sleep(1.0)
for i in range(5):
  logging.debug("append item %d to queue" % (i))
  q.put(i)

time.sleep(2.0)
```

:warning: `queue.Queue` is not **process-safe**, use `multiprocessing.Queue` instead.

---

class: top

# Multiprocessing: `multiprocessing` module

## .hcenter[\[multiprocessing/example16.py\]]
```Python
#!/usr/bin/env python3

import logging
import multiprocessing
import time


logging.basicConfig(level = logging.DEBUG, format = '%(asctime)s.%(msecs)03d [%(levelname)s] (%(process)d) %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

*q = multiprocessing.Queue()
def worker(n):
  while True:
    logging.debug("wait for item")
    item = q.get()
    logging.debug("received item %d" % (item))
    time.sleep(0.2) # do something
*   # q.task_done()
    logging.debug("task done")

logging.debug("start")
for i in range(3):
  t = multiprocessing.Process(name = 'THREAD-%01d' % (i), target = worker, args = (i,))
  t.daemon = True
  t.start()

time.sleep(1.0)
for i in range(5):
  logging.debug("append item %d to queue" % (i))
  q.put(i)

time.sleep(2.0)
```

---

# Multiprocessing: `multiprocessing` module

## .hcenter[Shell session]
```shell
$ multiprocessing/example16.py
2023-05-03 22:35:08.504 [DEBUG] (9399) start
2023-05-03 22:35:08.506 [DEBUG] (9400) wait for item
2023-05-03 22:35:08.507 [DEBUG] (9401) wait for item
2023-05-03 22:35:08.507 [DEBUG] (9402) wait for item
2023-05-03 22:35:09.506 [DEBUG] (9399) append item 0 to queue
2023-05-03 22:35:09.507 [DEBUG] (9399) append item 1 to queue
2023-05-03 22:35:09.507 [DEBUG] (9399) append item 2 to queue
2023-05-03 22:35:09.507 [DEBUG] (9400) received item 0
2023-05-03 22:35:09.507 [DEBUG] (9401) received item 1
2023-05-03 22:35:09.507 [DEBUG] (9399) append item 3 to queue
2023-05-03 22:35:09.507 [DEBUG] (9399) append item 4 to queue
2023-05-03 22:35:09.507 [DEBUG] (9402) received item 2
2023-05-03 22:35:09.707 [DEBUG] (9401) task done
2023-05-03 22:35:09.707 [DEBUG] (9400) task done
2023-05-03 22:35:09.708 [DEBUG] (9401) wait for item
2023-05-03 22:35:09.708 [DEBUG] (9401) received item 3
2023-05-03 22:35:09.708 [DEBUG] (9402) task done
2023-05-03 22:35:09.708 [DEBUG] (9402) wait for item
2023-05-03 22:35:09.708 [DEBUG] (9402) received item 4
2023-05-03 22:35:09.708 [DEBUG] (9400) wait for item
2023-05-03 22:35:09.908 [DEBUG] (9401) task done
2023-05-03 22:35:09.908 [DEBUG] (9402) task done
2023-05-03 22:35:09.908 [DEBUG] (9402) wait for item
2023-05-03 22:35:09.908 [DEBUG] (9401) wait for item
```

:arrow_right: Exactly the same behavior as `threading/example16.py` :v:

---

# Multiprocessing: `multiprocessing` module

:arrow_right: The `multiprocessing` module can do a lot more than "emulating" the `threading` module:
* `multiprocessing.Pool` object:

```Python
from multiprocessing import Pool

def f(x):
  return x*x

p = Pool(5)
print(p.map(f, [1, 2, 3])) # [1, 4, 9]
```

* `multiprocessing.Pipe`: thread- and process-safe **duplex pipe**,
* local and **remote** multiprocessing,

---

# Multiprocessing: `multiprocessing` module

.hcenter.w100[![](images/remote_multiprocessing.png)]

---

# Multiprocessing: `multiprocessing` module

## :arrow_right: Remote multiprocessing !

## .hcenter[\[multiprocessing/server.py\]]
```Python
#!/usr/bin/env python3
from multiprocessing.managers import BaseManager
import multiprocessing

queue = multiprocessing.Queue()
class QueueManager(BaseManager): pass
QueueManager.register('get_queue', callable=lambda:queue)
m = QueueManager(address=('', 50000), authkey=b'abracadabra')
s = m.get_server()
s.serve_forever()
```

## .hcenter[\[multiprocessing/client.py\]]
```Python
#!/usr/bin/env python3
from multiprocessing.managers import BaseManager

class QueueManager(BaseManager): pass
QueueManager.register('get_queue')
m = QueueManager(address=('127.0.0.1', 50000), authkey=b'abracadabra')
m.connect()
queue = m.get_queue()
queue.put('hello')
print(queue.get())
```

## .hcenter[Shell session]
```shell
$ python3 multiprocessing/server.py &
[1] 10929
$ python3 multiprocessing/client.py 
hello
*$ kill 10929
```

---

# Multiprocessing: Conclusions

## `threading` module

:arrow_right: It is **possible and easy** to use **multithreading** in `Python`  
:warning: Beware of the GIL in your multithreaded code !
:arrow_right: OK if IO-intensive functions.

## `multiprocessing` module - local usage
:arrow_right: It is **possible and easy** to use **multiple processes** in `Python`  

## `multiprocessing` module - remote usage
:arrow_right: It is **possible and easy** to use **multiple remote processes** in `Python`  

## Other modules
:arrow_right: Some specialized modules may be **more efficient** for local or remote multiprocessing in `Python`:
* `pymp`: OpenMP-like for `Python`, **no GIL issue** (on systems with `fork()` support)
* `asyncio`: manage concurrent coroutines
* `multiprocessing.Pool`: easily distribute function evaluation
* [`mpi4py`](mpi4py.html): MPI for `Python`
* etc...

    </textarea>

    <script src="core/javascript/remark.js"></script>
    <script src="core/javascript/katex.min.js"></script>
    <script src="core/javascript/auto-render.min.js"></script>
    <script src="core/javascript/emojify.js"></script>
    <script src="core/javascript/mermaid.js"></script>
    <script src="core/javascript/term.js"></script>
    <script src="core/javascript/jquery-2.1.1.min.js"></script>
    <script src="core/javascript/extend-jquery.js"></script>
    <script src="core/javascript/cinescript.js"></script>
    <script src="core/javascript/gitgraph.js"></script>
    <script>

    // === Remark.js initialization ===
    var slideshow = remark.create({
      highlightStyle: 'monokai',
      countIncrementalSlides: false,
      highlightLines: true
    });

    // === Mermaid.js initialization ===
    mermaid.initialize({
      startOnLoad: false,
      cloneCssStyles: false,
      flowchart:{
        height: 50
      },
      sequenceDiagram:{
        width: 110,
        height: 30
      }
    });

    function initMermaid(s) {
      var diagrams = document.querySelectorAll('.mermaid');
      var i;
      for(i=0;i<diagrams.length;i++){
        if(diagrams[i].offsetWidth>0){
          mermaid.init(undefined, diagrams[i]);
        }
      }
    }

    slideshow.on('afterShowSlide', initMermaid);
    initMermaid(slideshow.getSlides()[slideshow.getCurrentSlideIndex()]);

    
    // === Emojify.js initialization ===
    emojify.run();

    // === Cinescript initialization ===
    $(document).ready(init_cinescripts);

    renderMathInElement(document.body,{delimiters: [{left: "$$", right: "$$", display: true}, {left: "\\(", right: "\\)", display: false}], ignoredTags: [] });

    </script>
  </body>
</html>

